{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pybrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as pylab\n",
    "import PIL\n",
    "pylab.rcParams['figure.figsize']= 16,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybrain import FeedForwardNetwork\n",
    "from pybrain import LinearLayer,SigmoidLayer\n",
    "from pybrain import FullConnection\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "from pybrain import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implementar SKLEARN para el procesamiento paralelo"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "READING FROM CSV WITH PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = pd.read_csv('resources/Consulta_Banxico.csv', sep=',', encoding='latin1', skiprows=16, skip_blank_lines=True)\n",
    "column = rawData.columns.values\n",
    "rawData\n",
    "Data = rawData.drop(rawData.index[:2])\n",
    "Data = Data.reset_index(drop = True)\n",
    "Data.columns = ['Fecha' , 'Tasa de crecimiento Mensual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan los 2 primeros indices debido a que no son utiles ( es texto y la primera observaci√≥n no tiene valor) y se crea la estructura de Serie (para la serie de tiempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS = pd.Series(Data['Tasa de crecimiento Mensual'].astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS.index= Data['Fecha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "TS.plot(style='o-', label = 'Series')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFFN(inNeurons,hiddenNeurons):\n",
    "    ffn = FeedForwardNetwork()\n",
    "    inLayer = LinearLayer(inNeurons)\n",
    "    hiddenLayer = SigmoidLayer(hiddenNeurons)\n",
    "    outLayer = LinearLayer(1)\n",
    "    ffn.addInputModule(inLayer)\n",
    "    ffn.addModule(hiddenLayer)\n",
    "    ffn.addOutputModule(outLayer)\n",
    "    in_to_hidden = FullConnection(inLayer,hiddenLayer)\n",
    "    hidden_to_out = FullConnection(hiddenLayer,outLayer)\n",
    "    ffn.addConnection(in_to_hidden)\n",
    "    ffn.addConnection(hidden_to_out)\n",
    "    ffn.sortModules()\n",
    "    return ffn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DataMatrix_Output(values,TS, lags):\n",
    "    dataSet = np.zeros((len(values)-(lags), lags))\n",
    "    for x in xrange(len(values)-(lags)):\n",
    "        dataSet[x] = values[x: x+lags]\n",
    "    output = TS[lags:]    \n",
    "    return dataSet,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DS(dataMatrix,output,lags):\n",
    "    DS = datasets.SupervisedDataSet(12, 1)\n",
    "    for x in xrange(len(dataMatrix)):\n",
    "        DS.appendLinked(dataMatrix[x], output[x])\n",
    "    return DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataM, output = create_DataMatrix_Output(Data['Tasa de crecimiento Mensual'],TS,lags)\n",
    "TrainM = dataM[:(len(dataM)-2*12)]\n",
    "TrainO = output[:(len(dataM)-2*12)]\n",
    "ValM = dataM[(len(dataM)-2*12):(len(dataM)-12)]\n",
    "ValO = output[(len(dataM)-2*12):(len(dataM)-12)]\n",
    "##TestM = dataM[(len(dataM)-lags):]\n",
    "##TestO = output[(len(dataM)-lags):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DataSets(lags):\n",
    "    dataM, output = create_DataMatrix_Output(Data['Tasa de crecimiento Mensual'],TS,lags)\n",
    "    TrainM = dataM[:(len(dataM)-2*12)]\n",
    "    TrainO = output[:(len(dataM)-2*12)]\n",
    "    ValM = dataM[(len(dataM)-2*12):(len(dataM)-12)]\n",
    "    ValO = output[(len(dataM)-2*12):(len(dataM)-12)]\n",
    "    TrainDS = create_DS(TrainM,TrainO,lags)\n",
    "    ValDS = create_DS(ValM,ValO,lags)\n",
    "    return TrainDS,ValDS,ValO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainFNN(ffn,TrainDS,LearnRate,MaxEpochs):\n",
    "    trainer = BackpropTrainer(ffn, TrainDS,learningrate = LearnRate )\n",
    "    trainer.trainUntilConvergence(verbose= False, maxEpochs=MaxEpochs,validationProportion= 0.1,continueEpochs= 10)\n",
    "    return ffn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ValPredictions(ffn,ValDS):\n",
    "    predictions = ffn.activateOnDataset(ValDS)\n",
    "    predictions = predictions.reshape(1,12)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MSE(predictions, output):\n",
    "    return  np.mean(np.sum((output - predictions)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ValidationTest(ffn, ValDS,output, lags):\n",
    "    predictions = ffn.activateOnDataset(ValDS)\n",
    "    predictions = predictions.reshape(1,lags)\n",
    "    mse = get_MSE(predictions[0],output)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SolutionValidation(meanPredictions,mse,bestFFN,bestMSE,bestPredictions,lags,an,maxE,LearnR):\n",
    "        if(mse < bestMSE):\n",
    "            bestFFN = [lags,an,maxE,LearnR]\n",
    "            bestMSE = mse\n",
    "            bestPredictions = meanPredictions\n",
    "        return bestMSE,bestFFN, bestPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validation(ParametersList):\n",
    "    bestParameters = [len(ParametersList)]\n",
    "    bestRNA = []\n",
    "    bestMSE = 10000000000000000\n",
    "    bestPredicts = []\n",
    "    for lags in ParametersList[0]:    \n",
    "        TrainDS,ValDS,ValOutput = create_DataSets(lags)\n",
    "        for an in ParametersList[1]:\n",
    "            ffn = buildFFN(lags,an)\n",
    "            for maxE in ParametersList[2]:\n",
    "                for learnR in ParametersList[3]:\n",
    "                    trainFNN(ffn,TrainDS,learnR,maxE)\n",
    "                    MSEsum = 0 \n",
    "                    sumPredictions = np.zeros((1,lags))\n",
    "                    for epoch in xrange(100):\n",
    "                        predictions = get_ValPredictions(ffn,ValDS)\n",
    "                        mse = ValidationTest(ffn, ValDS,ValOutput, lags)\n",
    "                        MSEsum += mse\n",
    "                        sumPredictions += predictions\n",
    "                    MSEmean = MSEsum / 100\n",
    "                    MeanPredictions = sumPredictions / 100\n",
    "                    bestMSE,bestRNA,bestPredicts = SolutionValidation(MeanPredictions,MSEmean,bestRNA,bestMSE,bestPredicts,lags,an,maxE,learnR)\n",
    "    return bestRNA, MSEmean, bestPredicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ParametersList = [[12],[3],[1000],[0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = 12\n",
    "TrainDS1, ValDS1, ValOutput1 = create_DataSets(lags)\n",
    "ffn = buildFFN(lags,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSEsum = 0\n",
    "sumPredictions = np.zeros((1,lags))\n",
    "Predicts = np.zeros((10,lags))\n",
    "for epoch in xrange(10):\n",
    "    ffn = trainFNN(ffn,TrainDS1,0.1,1000)\n",
    "    predictions = get_ValPredictions(ffn,ValDS1)\n",
    "    Predicts[epoch]  = predictions\n",
    "    mse = ValidationTest(ffn, ValDS1,ValOutput1, lags)\n",
    "    MSEsum += mse\n",
    "    sumPredictions += predictions\n",
    "MSEmean = MSEsum / 10\n",
    "MeanPredictions = sumPredictions / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}